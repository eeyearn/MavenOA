# Maven Drive Copilot - Take Home Assessment

Welcome! This is a **2-3 hour coding assessment** where you'll build the backend for a Google Drive semantic search and chat system.

Please create a Fork of this repository to continue building!

## üéØ What You'll Build

A system that:
1. **Ingests** Google Drive files into a vector database
2. **Searches** documents using semantic search
3. **Chats** with an LLM using retrieved context (RAG)

## ‚úÖ What's Already Done

We've built everything except the core logic:

- ‚úÖ **Basic Frontend Setup** - React + TypeScript 
- ‚úÖ **Basic Backend Structure** - FastAPI with all routes
- ‚úÖ **Google OAuth Integration** - Full authentication flow
- ‚úÖ **Type Definitions** - All Pydantic models
- ‚úÖ **API Routes** - All endpoints wired up
- ‚úÖ **Drive Service** - Google Drive API integration

## ‚ö†Ô∏è What YOU Need to Implement

You need to implement **3 core functions**:

### 1. Ingestion Service (60-90 minutes)
**File:** `backend/src/services/ingestion_service.py`

**What it should do:**
- Fetch files from Google Drive
- Extract text from different file types
- Chunk content intelligently
- Generate embeddings
- Store in vector database with metadata

**Key considerations:**
- Start with Google Docs only (easiest)
- Use simple fixed-size chunking (500-1000 chars)
- Store metadata: file_id, file_name, path, chunk_index

### 2. Search Tool (45-60 minutes)
**File:** `backend/src/tools/search_tool.py`

**Function:** `search_documents()`

**What it should do:**
- Generate embedding for search query
- Query vector database for similar chunks
- Apply folder/file filters if provided
- Format results with snippets and highlights
- Return top N results with relevance scores

**Key considerations:**
- Return 5-10 most relevant results
- Calculate relevance scores (0-1 range)
- Include file metadata in results

### 3. Chat Service (30-45 minutes)
**File:** `backend/src/services/chat_service.py`

**What it should do:**
- Use `search_documents()` to find relevant context
- Build prompt with context and conversation history (optional)
- Call LLM API to generate response
- Extract and return source citations

**Key considerations:**
- Focus on ingestion and search first

## üöÄ Quick Start

### 1. Clone and Setup (5 minutes)

```bash
# Clone the repo
git clone <repo-url>
cd MavenOA

# Run the dev script (installs everything and starts services)
./dev.sh
```

The script will:
- Install Python and Node dependencies
- Prompt you to configure `.env`
- Start both backend and frontend
- Show live logs

### 2. Configure Google OAuth (10 minutes)

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project
3. Enable **Google Drive API**
4. Create OAuth 2.0 credentials:
   - Type: Web application
   - Authorized redirect URI: `http://localhost:8000/api/auth/callback`
5. Copy Client ID and Secret to `backend/.env`:

```env
GOOGLE_CLIENT_ID=your_client_id_here
GOOGLE_CLIENT_SECRET=your_client_secret_here
GOOGLE_REDIRECT_URI=http://localhost:8000/api/auth/callback
```

6. Configure OAuth Consent Screen:
   - User Type: **External**
   - Add your email as a test user
   - Add scope: `../auth/drive.readonly`

### 3. Choose Your Tech Stack (5 minutes)

Pick one from each category and add to `.env`:

**Vector Database (choose one):**
```bash
# ChromaDB (easiest - runs locally)
pip install chromadb

# OR Pinecone (cloud-hosted)
pip install pinecone-client
# Add to .env: PINECONE_API_KEY=xxx

# OR Qdrant (self-hosted or cloud)
pip install qdrant-client
```

**Embedding Model (choose one):**
```bash
# OpenAI (best quality)
pip install openai
# Add to .env: OPENAI_API_KEY=xxx

# OR Sentence Transformers (free, local)
pip install sentence-transformers

# OR Cohere
pip install cohere
# Add to .env: COHERE_API_KEY=xxx
```

**LLM for Chat (choose one):**
```bash
# OpenAI GPT-4/3.5
# Uses OPENAI_API_KEY from above

# OR Anthropic Claude
pip install anthropic
# Add to .env: ANTHROPIC_API_KEY=xxx

# OR Cohere
# Uses COHERE_API_KEY from above
```

### 4. Start Implementing (2-3 hours)

The implementation files:

```
backend/src/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion_service.py      # ‚ö†Ô∏è YOU IMPLEMENT THIS
‚îÇ   ‚îî‚îÄ‚îÄ chat_service.py           # ‚ö†Ô∏è YOU IMPLEMENT THIS
‚îî‚îÄ‚îÄ tools/
    ‚îî‚îÄ‚îÄ search_tool.py            # ‚ö†Ô∏è YOU IMPLEMENT THIS
```

Each file has:
- ‚úÖ Function signatures
- ‚úÖ Type hints
- ‚úÖ Detailed TODO comments
- ‚úÖ Helper function stubs


## üß™ Testing Your Implementation

### 1. Create Test Files in Google Drive

Create a few test documents:
- `Project Plan.docx` - "We are building a Drive copilot for Maven"
- `Meeting Notes.docx` - "Discussed the take-home assessment timeline"
- `Budget.docx` - "Engineering budget is $100k"

### 2. Test Ingestion

1. Open http://localhost:3000
2. Click "Connect Google Drive"
3. Authorize the app
4. Click "Start Ingestion"
5. Watch the progress bar
6. Check logs to verify chunks are being stored

### 3. Test Search

1. In the chat interface, type: "What are we building?"
2. Verify relevant results appear
3. Check that source attribution is correct
4. Try filtering by folder/file

### 4. Test Chat (if implemented)

1. Ask: "What's the engineering budget?"
2. Verify it finds the Budget document
3. Check that sources are cited
4. Try follow-up questions

## üìä Evaluation Criteria

We'll evaluate based on:

### 1. Functionality (40%)
- ‚úÖ Does ingestion work end-to-end?
- ‚úÖ Does search return relevant results?
- ‚úÖ Are sources properly attributed?
- ‚úÖ Does filtering work (folder/file)?

### 2. Code Quality (30%)
- ‚úÖ Clean, readable code
- ‚úÖ Proper error handling
- ‚úÖ Good function/variable names
- ‚úÖ Appropriate abstractions

### 3. Retrieval Quality (20%)
- ‚úÖ Relevance of search results
- ‚úÖ Quality of snippets/highlights
- ‚úÖ Handling of edge cases

### 4. Execution (10%)
- ‚úÖ Time management
- ‚úÖ What you accomplished in 2-3 hours
- ‚úÖ Clear commit messages


## ‚è±Ô∏è Time Management Suggestions

**Total: 3 hours**

### Setup (30 minutes)
- ‚úÖ Clone repo and read docs (10 min)
- ‚úÖ Configure Google OAuth (10 min)
- ‚úÖ Choose and install vector DB/embeddings (10 min)

### Implementation (90-120 minutes)
- ‚úÖ Ingestion Service (60-90 min)
  - File fetching and text extraction (20 min)
  - Chunking logic (15 min)
  - Embedding generation (15 min)
  - Vector DB storage (20 min)
  - Testing (10 min)

- ‚úÖ Search Tool (45-60 min)
  - Query embedding (10 min)
  - Vector search (15 min)
  - Result formatting (15 min)
  - Testing (15 min)

- ‚úÖ Chat Service (30-45 min)
  - Prompt building (15 min)
  - LLM integration (15 min)
  - Testing (10 min)

### Testing & Polish (15-30 minutes)
- ‚úÖ End-to-end testing (15 min)
- ‚úÖ Bug fixes and polish (15 min)

## üö® Common Pitfalls

1. **Over-engineering chunking** - Start simple! Fixed-size chunks work fine
2. **Forgetting metadata** - Store file_id, file_name, path with each chunk
3. **Not testing early** - Test ingestion with 1 file before processing all
4. **Ignoring error handling** - At least catch and log exceptions
5. **Spending too long on chat** - Focus on ingestion and search first

## üìö Helpful Resources

### Vector Databases
- [ChromaDB Docs](https://docs.trychroma.com/) - Easiest to set up
- [Pinecone Docs](https://docs.pinecone.io/)
- [Qdrant Docs](https://qdrant.tech/documentation/)

### Embeddings
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
- [Sentence Transformers](https://www.sbert.net/)

### LLMs
- [OpenAI API](https://platform.openai.com/docs/api-reference)
- [Anthropic Claude](https://docs.anthropic.com/)

### Google Drive API
- [Drive API Reference](https://developers.google.com/drive/api/v3/reference)

## üì¶ Submission

When you're done:

1. **Commit your code** with clear commit messages
2. **Push to GitHub**
3. **Email us** at yuv2bindal@gmail.com and sultan.shayaan@gmail.com with:
   - Link to your repository
   - Hours spent
   - Brief description of your approach (2-3 sentences)
   - Tech stack choices (vector DB, embeddings, LLM)
   - Any challenges or trade-offs
   - What you'd improve with more time

## ‚ùì FAQ

**Q: What if I can't finish in 2-3 hours?**
A: Submit what you have! We value quality over completeness. Show us your best work.

**Q: Can I use AI coding assistants (GitHub Copilot, Claude, etc.)?**
A: Yes! But make sure you understand the code. We'll discuss your implementation.

**Q: Which vector DB should I use?**
A: ChromaDB is easiest for local development. Pinecone is great for cloud. Or surprise us with an even better DB.

**Q: Do I need to implement chat with streaming?**
A: It's optional. Focus on ingestion and search first. Chat with streaming is a bonus. Otherwise, just a simple chat is alright!

**Q: Can I modify the frontend or services?**
A: You can, but focus on implementing the tools. The architecture is already set up.

**Q: What about authentication persistence?**
A: Current implementation keeps credentials in memory. That's fine for this assessment.

**Q: How do I handle large files?**
A: Start simple - just handle Google Docs. If time permits, add PDF support.

**Q: Should I write tests?**
A: Manual testing is fine. Automated tests are a bonus if you have time.

## üéØ Success Looks Like

At minimum (for a passing submission):
- ‚úÖ Ingestion works for Google Docs
- ‚úÖ Search returns relevant results
- ‚úÖ Sources are properly attributed
- ‚úÖ Code is clean and readable

Bonus points for:
- ‚≠ê Handling multiple file types
- ‚≠ê Smart chunking strategies
- ‚≠ê Chat implementation
- ‚≠ê Great result snippets/highlights
- ‚≠ê Robust error handling

## üÜò Need Help?

If you run into issues:

1. **Check the logs** - `logs/backend.log` and `logs/frontend.log`
2. **Read the TODOs** - Each file has detailed implementation guidance
3. **Check the examples** - Code comments show example structures
4. **Email us** - We're happy to clarify requirements or help with setup

---

**Good luck!** We're excited to see what you build. Take your time, write clean code, and have fun! üöÄ
